{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jRKtwB5rZaRa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import json\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Must have mapping of id to array of genre labels\n",
        "# e.g. for id 1, [0,0,1,0,1,0]\n",
        "with open('genres.json') as f:\n",
        "  label_mapper = json.load(f)"
      ],
      "metadata": {
        "id": "NFCGJ9rxb1Kh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_first(data_home, corrupt_ids, label_mapper = label_mapper, track_ids = None):\n",
        "    \"\"\"\n",
        "    Load data from a specified music dataset and return the audio file paths and their corresponding labels.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home : str\n",
        "        The root directory where the dataset is stored.\n",
        "    dataset_name : str, optional\n",
        "        The name of the dataset to load, by default 'gtzan_genre'.\n",
        "    version : str, optional\n",
        "        The version of the dataset to load, by default '1.0'.\n",
        "    track_ids : list of str, optional\n",
        "        A list of track IDs to load from the dataset, by default None. If None, all tracks in the dataset will be loaded.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    audio_file_paths : list of str\n",
        "        A list of audio file paths from the specified dataset.\n",
        "    labels : list of int\n",
        "        A list of corresponding labels for the audio files.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> data_home = \"/path/to/data_directory\"\n",
        "    >>> dataset_name = \"gtzan_genre\"\n",
        "    >>> version = \"mini\"\n",
        "    >>> track_ids = [\"track_1\", \"track_2\"]\n",
        "    >>> audio_file_paths, labels = load_data(data_home, dataset_name, version, track_ids)\n",
        "    \"\"\"\n",
        "\n",
        "    audio_file_paths = []\n",
        "    labels = []\n",
        "    ids = []\n",
        "    print(data_home)\n",
        "\n",
        "    for file in os.listdir(data_home):\n",
        "      #print(file)\n",
        "      file_str = str(file)[:-4]\n",
        "      if file_str not in corrupt_ids:\n",
        "        audio_file_paths.append(file_str)\n",
        "        ids.append(file_str)\n",
        "        labels.append(label_mapper[file_str])\n",
        "\n",
        "\n",
        "    return audio_file_paths, labels, ids"
      ],
      "metadata": {
        "id": "rPFIb2PQZgWB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_home, label_mapper = label_mapper, track_ids = None):\n",
        "    \"\"\"\n",
        "    Load data from a specified music dataset and return the audio file paths and their corresponding labels.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home : str\n",
        "        The root directory where the dataset is stored.\n",
        "    dataset_name : str, optional\n",
        "        The name of the dataset to load, by default 'gtzan_genre'.\n",
        "    version : str, optional\n",
        "        The version of the dataset to load, by default '1.0'.\n",
        "    track_ids : list of str, optional\n",
        "        A list of track IDs to load from the dataset, by default None. If None, all tracks in the dataset will be loaded.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    audio_file_paths : list of str\n",
        "        A list of audio file paths from the specified dataset.\n",
        "    labels : list of int\n",
        "        A list of corresponding labels for the audio files.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> data_home = \"/path/to/data_directory\"\n",
        "    >>> dataset_name = \"gtzan_genre\"\n",
        "    >>> version = \"mini\"\n",
        "    >>> track_ids = [\"track_1\", \"track_2\"]\n",
        "    >>> audio_file_paths, labels = load_data(data_home, dataset_name, version, track_ids)\n",
        "    \"\"\"\n",
        "\n",
        "    audio_file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    track_ids = [x.decode() for x in track_ids]\n",
        "    #print(\"in load data\")\n",
        "    #print(\"load data track ids\")\n",
        "    #print(track_ids)\n",
        "\n",
        "    for file in os.listdir(data_home):\n",
        "      file_str = str(file)[2:-5]\n",
        "      #file_str = str(file)\n",
        "      #print(\"file_str:\")\n",
        "      #print(file_str)\n",
        "      if file_str in track_ids:\n",
        "        #print(\"path \",file_str)\n",
        "        #print(\"label \",label_mapper[file_str])\n",
        "        audio_file_paths.append(file)\n",
        "        labels.append(label_mapper[file_str])\n",
        "    #print(\"at end\")\n",
        "    #print(labels)\n",
        "    audio_file_paths = [x.decode() for x in audio_file_paths]\n",
        "    #print(audio_file_paths)\n",
        "    return audio_file_paths, labels"
      ],
      "metadata": {
        "id": "8ROXB6wkZiFw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_audio(audio, sample_rate, audio_seg_size, segments_overlap):\n",
        "    \"\"\"\n",
        "    Segment audio into windows with a specified size and overlap. Padding is added only to the\n",
        "    last window.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    audio : np.ndarray\n",
        "        The audio signal to be segmented.\n",
        "    sample_rate : int\n",
        "        The sampling rate of the audio signal.\n",
        "    audio_seg_size : float\n",
        "        The duration of each window in seconds.\n",
        "    segments_overlap : float\n",
        "        The duration of the overlap between consecutive windows in seconds.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    audio_windows : list of np.ndarray\n",
        "        A list of windows of the audio signal.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> import librosa\n",
        "    >>> y, sr = librosa.load(librosa.ex('trumpet'))\n",
        "    >>> audio_windows = window_audio(y, sr, audio_seg_size=1, segments_overlap=0.5)\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    import math\n",
        "    audio_windows = []\n",
        "    # Calculate the window size in samples\n",
        "    # x samples / second * y seconds = z samples in a given segment\n",
        "    window_size = int(sample_rate * audio_seg_size)\n",
        "\n",
        "\n",
        "    # Calculate the overlap size in samples\n",
        "    # same math as above\n",
        "    overlap_size = int(sample_rate * segments_overlap)\n",
        "\n",
        "\n",
        "    # Iterate through the audio signal, extracting windows\n",
        "    start_pos = 0\n",
        "    idx = 0\n",
        "    at_end = False\n",
        "\n",
        "    while not at_end:\n",
        "        # current window goes from start to start + size of the window\n",
        "        # If the window end is within the audio length, extract the window\n",
        "        if ((start_pos + window_size) - overlap_size) < len(audio):\n",
        "          audio_window = audio[start_pos : start_pos + window_size]\n",
        "          audio_windows.append(audio_window)\n",
        "          \n",
        "        # Padding the last window with zeros if it extends beyond the audio length\n",
        "        else:\n",
        "          audio_window = audio[start_pos:]\n",
        "          at_end = True\n",
        "          zeros_to_add = window_size - len(audio_window)\n",
        "          for _ in range(zeros_to_add):\n",
        "            audio_window = np.append(audio_window,0)\n",
        "          audio_windows.append(audio_window)\n",
        "        # Add the window to the list of audio windows\n",
        "        \n",
        "        # Update the start position for the next window, considering the overlap\n",
        "        start_pos = (start_pos + window_size) - overlap_size\n",
        "        idx += 1\n",
        "\n",
        "    #print(\"out of while loop\")\n",
        "    return(audio_windows)"
      ],
      "metadata": {
        "id": "3hVCRfzpZly-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mel_spectrogram(audio, sample_rate=22050, n_mels=128, hop_length=512):\n",
        "    \"\"\"\n",
        "    Compute the normalized Mel spectrogram of an audio signal.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    audio : np.ndarray\n",
        "        Input audio signal as a 1D numpy array.\n",
        "    sample_rate : int, optional\n",
        "        Sampling rate of the audio signal, by default 22050.\n",
        "    n_mels : int, optional\n",
        "        Number of Mel bands to generate, by default 128.\n",
        "    hop_length : int, optional\n",
        "        Number of samples between successive frames, by default 512.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Mel spectrogram as a 2D numpy array.\n",
        "\n",
        "    \"\"\"\n",
        "    # Hint: use librosa melspectrogram and librosa power_to_db\n",
        "    from librosa import power_to_db\n",
        "    from librosa.feature import melspectrogram\n",
        "\n",
        "    # Compute Mel spectrogram from the audio signal\n",
        "    spectrogram = melspectrogram(y = audio, sr = sample_rate, hop_length = hop_length, n_mels = n_mels)\n",
        "    \n",
        "    # Convert the Mel spectrogram to dB scale\n",
        "    spectrogram = power_to_db(spectrogram)\n",
        "    \n",
        "\n",
        "    return spectrogram "
      ],
      "metadata": {
        "id": "S1H3rJD0ZooW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def win_generator(data_home, augment, track_ids=None, sample_rate=22050, pitch_shift_steps=2,\n",
        "                   n_mels=128, hop_length=512, audio_seg_size=1, segments_overlap=0.5, shuffle=True):\n",
        "    \"\"\"\n",
        "    Generator function that yields Mel spectrograms and labels from the specified dataset, with optional data augmentation. \n",
        "    Audio is broken down in small windows, the spectrogram is computed and yielded along with the label. \n",
        "    The label of the window is assumed to be the same as the label for the entire track.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home : str\n",
        "        The root directory where the dataset is stored.\n",
        "    augment : bool\n",
        "        Whether to apply data augmentation (pitch shifting) to the audio.\n",
        "    track_ids : list of str, optional\n",
        "        A list of track IDs to load from the dataset, by default None. If None, all tracks in the dataset will be loaded.\n",
        "    sample_rate : int, optional\n",
        "        The sample rate at which to load the audio, by default 22050.\n",
        "    pitch_shift_steps : int, optional\n",
        "        The number of steps by which to shift the pitch for data augmentation, by default 2.\n",
        "    n_mels : int, optional\n",
        "        The number of Mel bands to generate, by default 128.\n",
        "    hop_length : int, optional\n",
        "        The number of samples between successive frames, by default 512.\n",
        "    audio_seg_size : float, optional\n",
        "        The size of audio segments in seconds, by default 1.\n",
        "    segments_overlap : float, optional\n",
        "        The overlap between audio segments in seconds, by default 0.5.\n",
        "    shuffle : bool, optional\n",
        "        Whether to shuffle the data before iterating, by default True.\n",
        "\n",
        "    Yields\n",
        "    ------\n",
        "    spectrogram : np.ndarray\n",
        "        A NumPy array containing the Mel spectrogram data.\n",
        "    label : int\n",
        "        The corresponding label for the spectrogram.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> data_home = \"/path/to/data_directory\"\n",
        "    >>> augment = True\n",
        "    >>> track_ids = [\"track_1\", \"track_2\"]\n",
        "    >>> generator = win_generator(data_home, augment, track_ids)\n",
        "    >>> for spectrogram, label in generator:\n",
        "    ...     # Process spectrogram and label\n",
        "    \"\"\"\n",
        "\n",
        "    # Get list of audio paths and their corresponding labels\n",
        "    #print(\"in generator\")\n",
        "    #print(label_mapper)\n",
        "    #print(\"track ids = \", track_ids)\n",
        "    audio_file_paths, labels = load_data(data_home, label_mapper, track_ids=track_ids)\n",
        "    #print([audio_file_paths,labels])\n",
        "\n",
        "    # Convert labels to numpy array\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Shuffle data\n",
        "    if shuffle:\n",
        "      idxs = np.random.permutation(len(labels))\n",
        "      audio_file_paths = [audio_file_paths[i] for i in idxs]\n",
        "      labels = labels[idxs]\n",
        "\n",
        "\n",
        "    for idx in range(len(audio_file_paths)):\n",
        "\n",
        "        # Load audio at given sample_rate and label\n",
        "        label = labels[idx]\n",
        "        #audio, _ = librosa.load(audio_file_paths[idx], sr=sample_rate)\n",
        "        #print(\"data_home \",data_home)\n",
        "        print(\"file path \", audio_file_paths[idx])\n",
        "        audio, _ = librosa.load(data_home.decode()+audio_file_paths[idx], sr=sample_rate)\n",
        "\n",
        "        # Shorten audio to 29s due to imprecisions in duration of GTZAN\n",
        "        # (ensures same duration files)\n",
        "        audio = audio[:29*sample_rate]\n",
        "\n",
        "        # Apply augmentation\n",
        "        if augment:\n",
        "            audio = pitch_shift_audio(audio, sample_rate, pitch_shift_steps)\n",
        "\n",
        "        # Compute audio windowing\n",
        "        audio_windows = window_audio(audio, sample_rate, audio_seg_size, segments_overlap)\n",
        "\n",
        "        # Loop over windows\n",
        "        for window in audio_windows:\n",
        "            \n",
        "            # Compute Mel spectrogram\n",
        "            spectrogram = compute_mel_spectrogram(window, sample_rate, n_mels, hop_length)\n",
        "            spectrogram = np.expand_dims(spectrogram, axis=2)\n",
        "            if spectrogram.shape != (128,44,1):\n",
        "              print(audio_file_paths[idx])\n",
        "              print(\"is a BAD ID\")\n",
        "              continue\n",
        "            #print(spectrogram)\n",
        "            #print(\"shape\")\n",
        "            #print(spectrogram.shape)\n",
        "\n",
        "            #print(\"leaving generator\")\n",
        "            yield spectrogram, label"
      ],
      "metadata": {
        "id": "4WqHIS94ZqDj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data_generator, input_args, input_shape):\n",
        "    \"\"\"\n",
        "    Create a TensorFlow dataset from a data generator function along with the specified input arguments and shape.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_generator : callable\n",
        "        The data generator function to use for creating the dataset.\n",
        "    input_args : list\n",
        "        A list containing the arguments to be passed to the data generator function.\n",
        "    input_shape : tuple\n",
        "        A tuple representing the shape of the input data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataset : tf.data.Dataset\n",
        "        A TensorFlow dataset created from the data generator function.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> def sample_generator():\n",
        "    ...     for i in range(10):\n",
        "    ...         yield np.random.random((4, 4)), i\n",
        "    >>> input_args = []\n",
        "    >>> input_shape = (4, 4, 1)\n",
        "    >>> dataset = create_dataset(sample_generator, input_args, input_shape)\n",
        "    \"\"\"\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "      data_generator,\n",
        "      args=input_args,\n",
        "      output_signature=(\n",
        "          tf.TensorSpec(shape=input_shape, dtype=tf.float32),\n",
        "          #tf.TensorSpec(shape=(), dtype=tf.uint8)))\n",
        "          tf.TensorSpec(shape=(10,), dtype=tf.uint8)))\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "8Bbo8Aa-ZsWV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wav_generator(data_home, augment, track_ids=None, sample_rate=22050, pitch_shift_steps=2, shuffle=True):\n",
        "\n",
        "    # Hint: base your generator on the win_generator\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    audio_file_paths, labels = load_data(data_home, label_mapper, track_ids=track_ids)\n",
        "    print([audio_file_paths,labels])\n",
        "\n",
        "    # Convert labels to numpy array\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Shuffle data\n",
        "    if shuffle:\n",
        "      idxs = np.random.permutation(len(labels))\n",
        "      audio_file_paths = [audio_file_paths[i] for i in idxs]\n",
        "      labels = labels[idxs]\n",
        "\n",
        "\n",
        "    for idx in range(len(audio_file_paths)):\n",
        "\n",
        "        # Load audio at given sample_rate and label\n",
        "        label = labels[idx]\n",
        "        #audio, _ = librosa.load(audio_file_paths[idx], sr=sample_rate)\n",
        "        #print(\"data_home \",data_home)\n",
        "        print(\"file path \", audio_file_paths[idx])\n",
        "        audio, _ = librosa.load(data_home.decode()+audio_file_paths[idx], sr=sample_rate)\n",
        "\n",
        "        # Shorten audio to 29s due to imprecisions in duration of GTZAN\n",
        "        # (ensures same duration files)\n",
        "        audio = audio[:29*sample_rate]\n",
        "\n",
        "        # Apply augmentation\n",
        "        if augment:\n",
        "            audio = pitch_shift_audio(audio, sample_rate, pitch_shift_steps)\n",
        "\n",
        "        if audio.shape != (464000,):\n",
        "          continue\n",
        "        \n",
        "        yield audio, label"
      ],
      "metadata": {
        "id": "IW8NP3pEZ4RO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_yamnet_embedding(wav_data, yamnet):\n",
        "    \"\"\"\n",
        "    Run YAMNet to extract embeddings from the wav data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    wav_data : np.ndarray\n",
        "        The audio signal to be processed.\n",
        "    yamnet : tensorflow.keras.Model\n",
        "        The pre-trained YAMNet model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        The extracted embeddings from YAMNet.\n",
        "    \"\"\"\n",
        "    # Hint: check the tensorflow models to see how yamnet should be used\n",
        "    # YOUR CODE HERE\n",
        "    scores, embeddings, spectrogram = yamnet(wav_data)\n",
        "    return(embeddings)"
      ],
      "metadata": {
        "id": "toDbsOa5aA8S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reload_tcn(model_path, weights_path, optimizer, loss, metrics):\n",
        "    \"\"\"\n",
        "    Reload a TCN model from a JSON file and restore its weights. \n",
        "    Preferred method when dealing with custom layers.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_path : str\n",
        "        The path to the JSON file containing the model architecture.\n",
        "    weights_path : str\n",
        "        The path to the model weights file.\n",
        "    optimizer : str or tf.keras.optimizers.Optimizer\n",
        "        The optimizer to use when compiling the model.\n",
        "    loss : str or tf.keras.losses.Loss\n",
        "        The loss function to use when compiling the model.\n",
        "    metrics : list of str or tf.keras.metrics.Metric\n",
        "        The list of metrics to use when compiling the model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    reloaded_model : tf.keras.Model\n",
        "        The reloaded model with the restored weights.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> model_path = 'path/to/saved_model.json'\n",
        "    >>> weights_path = 'path/to/saved_weights.h5'\n",
        "    >>> optimizer = 'adam'\n",
        "    >>> loss = 'sparse_categorical_crossentropy'\n",
        "    >>> metrics = ['accuracy']\n",
        "    >>> reloaded_model = reload_tcn(model_path, weights_path, optimizer, loss, metrics)\n",
        "    \"\"\"\n",
        "    # Load the best checkpoint of the model from json file (due to custom layers)\n",
        "    \n",
        "    loaded_json = open(model_path, 'r').read()\n",
        "    reloaded_model = model_from_json(loaded_json, custom_objects={'TCN': TCN})\n",
        "\n",
        "    reloaded_model.compile(optimizer=optimizer, \n",
        "                         loss=loss, \n",
        "                       metrics=metrics)\n",
        "    # restore weights\n",
        "    reloaded_model.load_weights(weights_path)\n",
        "\n",
        "    return reloaded_model"
      ],
      "metadata": {
        "id": "aEsXWNxIaKUv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b0ZaOjqPaPnO"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}