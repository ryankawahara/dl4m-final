{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqZ4IpiwIRA1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import json\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data_home = '/content/drive/My Drive/dl4m_final/trailer_dataset/'"
      ],
      "metadata": {
        "id": "k-7CtTgjJKkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Must have id/label mapping\n",
        "# e.g. for id 1, [0,0,1,0,1,0]\n",
        "with open('genres.json') as f:\n",
        "  label_mapper = json.load(f)"
      ],
      "metadata": {
        "id": "HrvAlk6GWfy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils_audio as u\n",
        "import models_audio as m"
      ],
      "metadata": {
        "id": "UzDqPW_7dIxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some IDs cause model to crash - remove these\n",
        "corrupt_ids = [\"gYbW1F_c9eM\", \"VW-F1H-Nonk\", \"j9N0nvBITzk\", \"xNstK5rbzcw\", \"5tGgqyhCIXQ\", \"t2LI5OOifsQ\", \"lcwmDAYt22k\", \"RGyrxamYhUA\", \"vlEwqBrbPPU\"]"
      ],
      "metadata": {
        "id": "w3WlOzMQr0hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data in.  this loads file paths, labels, and ids\n",
        "\n",
        "train_data, train_labels, train_ids = u.load_data_first(data_home+\"train/audio\", corrupt_ids, label_mapper)\n",
        "val_data, val_labels, val_ids = u.load_data_first(data_home+\"validation/audio\", corrupt_ids, label_mapper)\n",
        "test_data, test_labels, test_ids = u.load_data_first(data_home+\"test/audio\", corrupt_ids, label_mapper)"
      ],
      "metadata": {
        "id": "-Hx8X01VLOci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check sizes\n",
        "print(len(train_ids))\n",
        "print(len(val_ids))\n",
        "print(len(test_ids))"
      ],
      "metadata": {
        "id": "D-poWDw-RWHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check ids\n",
        "print(train_ids[:5])\n",
        "print(val_ids[:5])\n",
        "print(test_ids[:5])"
      ],
      "metadata": {
        "id": "34968UOyV69q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Waveform\n",
        "sample_rate = 22050\n",
        "\n",
        "# Spectrogram\n",
        "n_mels = 128\n",
        "hop_length = 512\n",
        "audio_seg_size = 1 # seconds: how big the input to the CNN will be\n",
        "segments_overlap = audio_seg_size/2 # seconds: how much overlap between windows\n",
        "stft_length = int(np.ceil(sample_rate*audio_seg_size/hop_length))  # samples: how many windows the STFT will have\n",
        "\n",
        "# The CNN receives windows of spectrograms\n",
        "input_shape = (n_mels, stft_length, 1) \n",
        "\n",
        "# Augmentation\n",
        "augment = False\n",
        "pitch_shift_steps=2\n",
        "\n",
        "input_args_train = [data_home+'train/audio/', augment, train_ids, sample_rate, pitch_shift_steps, n_mels, hop_length, audio_seg_size, segments_overlap, True] # Last arg is shuffle\n",
        "input_args_val   = [data_home+'validation/audio/', augment, val_ids, sample_rate, pitch_shift_steps, n_mels, hop_length, audio_seg_size, segments_overlap, True]\n",
        "input_args_test  = [data_home+'test/audio/', augment, test_ids, sample_rate, pitch_shift_steps, n_mels, hop_length, audio_seg_size, segments_overlap, False]\n",
        "\n",
        "# create datasets\n",
        "dataset_train = u.create_dataset(u.win_generator, input_args_train, input_shape)\n",
        "dataset_val = u.create_dataset(u.win_generator, input_args_val, input_shape)\n",
        "dataset_test= u.create_dataset(u.win_generator, input_args_test, input_shape)"
      ],
      "metadata": {
        "id": "ZAyCKJ3AOOYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "id": "78XUwDRER43W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_val"
      ],
      "metadata": {
        "id": "xaihf-PwSAKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test"
      ],
      "metadata": {
        "id": "oG19SZF_SCXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check windows\n",
        "import matplotlib.pyplot as plt\n",
        "# Look at the windows fit into the model\n",
        "for sp, l in dataset_train.take(3):\n",
        "  #print(sp)\n",
        "  plt.imshow(sp)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "q3VX8_Q7VIzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = m.cnn_model(input_shape)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "vUcqeGH-TG7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train basic CNN\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "    filepath=f\"audio_convnet.keras\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(dataset_train.prefetch(tf.data.AUTOTUNE).batch(batch_size).cache(),\n",
        "    validation_data=dataset_val.prefetch(tf.data.AUTOTUNE).batch(batch_size).cache(),\n",
        "    epochs=10,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "metadata": {
        "id": "OJJGkWDiTIqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model and get test loss/accuracy\n",
        "model_reloaded = keras.models.load_model(\"audio_convnet.keras\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model_reloaded.evaluate(dataset_test.prefetch(tf.data.AUTOTUNE).batch(batch_size))\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "1BN_JUmveaZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get test predictions\n",
        "predictions = model_reloaded.predict(dataset_test.prefetch(tf.data.AUTOTUNE).batch(batch_size))"
      ],
      "metadata": {
        "id": "pozjMXN-2-S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predictions\n",
        "np.save(\"cnn_predictions\", predictions)"
      ],
      "metadata": {
        "id": "TUITVjku6drv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get test labels for each window\n",
        "test_labels_ = np.concatenate([y for x, y in dataset_test], axis = 0)"
      ],
      "metadata": {
        "id": "zfpT4iXI6Yaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape to match predictions\n",
        "test_labels_array = np.reshape(test_labels_,(32666,10))"
      ],
      "metadata": {
        "id": "guOr6j5a_G-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save labels\n",
        "np.save(\"cnn_test_labels_shaped\", test_labels_array)"
      ],
      "metadata": {
        "id": "_yDI06Nl_iwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set decision threshold\n",
        "y_pred_binary = (predictions < .5)"
      ],
      "metadata": {
        "id": "7o5S0584_l-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create confusion matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "confusion = multilabel_confusion_matrix(y_true = test_labels_array, y_pred = y_pred_binary)"
      ],
      "metadata": {
        "id": "SONwE_-p_3Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save confusion matrix\n",
        "np.save(\"cnn_confusion\", confusion)"
      ],
      "metadata": {
        "id": "Jb8J2Jcx_5YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at confusion matrix\n",
        "confusion"
      ],
      "metadata": {
        "id": "SDU4HsWU_-JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create classification report\n",
        "from sklearn.metrics import classification_report\n",
        "class_report = classification_report(test_labels_array, y_pred_binary, output_dict = True)\n",
        "class_report"
      ],
      "metadata": {
        "id": "_3vETI1SAIyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save classification report\n",
        "import pickle as pkl\n",
        "with open(\"cnn_class_report\", \"wb\") as c:\n",
        "  pkl.dump(class_report, c)"
      ],
      "metadata": {
        "id": "uw1Txr8yCFO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YAMNET"
      ],
      "metadata": {
        "id": "ii2ip25DemSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "\n",
        "# Waveform\n",
        "sample_rate = 16000  # 16kHz for Yamnet\n",
        "augment = False\n",
        "input_shape = (29*sample_rate,)\n",
        "\n",
        "input_args_train = [data_home+'train/audio/', augment, train_ids, sample_rate]\n",
        "input_args_val   = [data_home+'validation/audio/', augment, val_ids, sample_rate]\n",
        "input_args_test  = [data_home+'test/audio/', augment, test_ids, sample_rate]\n",
        "\n",
        "dataset_train = u.create_dataset(u.wav_generator, input_args_train, input_shape)\n",
        "dataset_val = u.create_dataset(u.wav_generator, input_args_val, input_shape)\n",
        "dataset_test= u.create_dataset(u.wav_generator, input_args_test, input_shape)\n"
      ],
      "metadata": {
        "id": "OpLhHfQcWp3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "import tensorflow_hub as hub\n",
        "yamnet = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "metadata": {
        "id": "j8dElAFYYmNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# may need to install keras-tcn if using for the first time\n",
        "#!pip install keras-tcn"
      ],
      "metadata": {
        "id": "AIA4QjHeZHQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tcn import TCN\n",
        "input_shape =  (60, 1024)\n",
        "# Create a tcn model that processes the embeddings\n",
        "tcn_yamnet = m.tcn_model(input_shape)\n",
        "\n",
        "# Print model summary\n",
        "tcn_yamnet.summary()"
      ],
      "metadata": {
        "id": "5HopkmPnY3rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mapping function to extract embeddings\n",
        "def map_function(audio, label):\n",
        "   return extract_yamnet_embedding(audio, yamnet), label\n",
        "   #return extract_yamnet_embedding(audio, yamnet), label\n",
        "\n",
        "# Check input shape from example in the data\n",
        "for e, l in dataset_train.map(map_function).take(1):\n",
        "    print(e.shape)"
      ],
      "metadata": {
        "id": "1-9rtJB9Y5bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train tcn using yamnet embeddings\n",
        "import keras\n",
        "\n",
        "batch_size = 32\n",
        "model_path = 'yamnet_model_BFC.json'\n",
        "model_weights = \"yamnet_weights_BFC.h5\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=model_weights,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = tcn_yamnet.fit(dataset_train.prefetch(tf.data.AUTOTUNE).map(map_function).batch(batch_size).cache(),\n",
        "    validation_data=dataset_val.prefetch(tf.data.AUTOTUNE).map(map_function).batch(batch_size).cache(),\n",
        "    epochs=20,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "model_as_json = tcn_yamnet.to_json()\n",
        "with open(model_path, \"w\") as json_file:\n",
        "    json_file.write(model_as_json)"
      ],
      "metadata": {
        "id": "SiOrsYKlZ2eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best checkpoint of the model \n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# set hyperparameters\n",
        "\n",
        "optimizer = 'adam'\n",
        "# can use normal BinaryCrossentropy as well\n",
        "loss = \"BinaryFocalCrossentropy\"\n",
        "metrics = [\"accuracy\"]\n",
        "model_path = \"yamnet_model_BFC.json\"\n",
        "model_weights = \"yamnet_weights_BFC.h5\"\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "tcn_yamnet_reloaded = u.reload_tcn(model_path, model_weights, optimizer, loss, metrics)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss_yamnet, test_acc_yamnet = tcn_yamnet_reloaded.evaluate(dataset_test.prefetch(tf.data.AUTOTUNE).map(map_function).batch(batch_size))\n",
        "print(f\"Test Loss: {test_loss_yamnet:.4f}, Test Accuracy: {test_acc_yamnet:.4f}\")"
      ],
      "metadata": {
        "id": "iHSIvzXZ5yg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get yamnet predictions\n",
        "predictions = tcn_yamnet_reloaded.predict(dataset_test.prefetch(tf.data.AUTOTUNE).map(map_function).batch(batch_size))"
      ],
      "metadata": {
        "id": "4NIPl-j3AJA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save yamnet predictions\n",
        "np.save(\"yamnet_predictions\", predictions)"
      ],
      "metadata": {
        "id": "bbVrJSOpAqYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get labels for yamnet\n",
        "test_labels_ = np.concatenate([y for x, y in dataset_test], axis = 0)"
      ],
      "metadata": {
        "id": "oFxeeNpbFoYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape labels\n",
        "test_labels_array = np.reshape(test_labels_,(562,10))"
      ],
      "metadata": {
        "id": "XK8f2-T2KWp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save labels\n",
        "np.save(\"yamnet_test_labels_shaped\", test_labels_array)"
      ],
      "metadata": {
        "id": "vSwlOtxRPnJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set decision threshold\n",
        "y_pred_binary = (predictions > 0.5) "
      ],
      "metadata": {
        "id": "nmkVnLivEwKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make confusion matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "confusion = multilabel_confusion_matrix(y_true = test_labels_array, y_pred = y_pred_binary)"
      ],
      "metadata": {
        "id": "5CgVnLkeE3h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view confusion matrix\n",
        "confusion"
      ],
      "metadata": {
        "id": "une0q0LrFxiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save confusion matrix\n",
        "np.save(\"confusion_yamnet\", confusion)"
      ],
      "metadata": {
        "id": "bpf2Q8-ELFLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make classifiction report\n",
        "from sklearn.metrics import classification_report\n",
        "class_report = classification_report(test_labels_array, y_pred_binary, output_dict = True)"
      ],
      "metadata": {
        "id": "IShm-LxHL8Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view classification report\n",
        "class_report"
      ],
      "metadata": {
        "id": "-a5iNNZEQxLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save classification report\n",
        "import pickle as pkl\n",
        "with open(\"yamnet_class_report\", \"wb\") as c:\n",
        "  pkl.dump(class_report, c)"
      ],
      "metadata": {
        "id": "arIBadvWSEDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGGISH"
      ],
      "metadata": {
        "id": "pi6qI-Nql8xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "# Load the model\n",
        "vggish = hub.load('https://tfhub.dev/google/vggish/1')"
      ],
      "metadata": {
        "id": "11CgmoXVaCgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_vggish_embedding(wav_data):\n",
        "  embeddings = vggish(wav_data)\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "hlIcEQcL2J9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mapping function to extract embeddings\n",
        "def map_function_vggish(audio, label):\n",
        "    embedding = extract_vggish_embedding(audio)\n",
        "    return embedding, label\n",
        "\n",
        "# Extract input shape from example in the data\n",
        "for e, l in dataset_train.map(map_function_vggish).take(1):\n",
        "    print(e.shape)"
      ],
      "metadata": {
        "id": "mOJJrwPl2LUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape =  (30, 128)\n",
        "# Create a tcn model that processes the embeddings\n",
        "tcn_vggish = m.tcn_model(input_shape)\n",
        "\n",
        "# Print model summary\n",
        "tcn_vggish.summary()"
      ],
      "metadata": {
        "id": "UiEJmLBt2MbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train vggish model\n",
        "import keras\n",
        "\n",
        "batch_size = 32\n",
        "model_path = 'vggish_model_class_weights.json'\n",
        "model_weights = \"vggish_weights_class_weights.h5\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=model_weights,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = tcn_vggish.fit(dataset_train.prefetch(tf.data.AUTOTUNE).map(map_function_vggish).batch(batch_size).cache(),\n",
        "    validation_data=dataset_val.prefetch(tf.data.AUTOTUNE).map(map_function_vggish).batch(batch_size).cache(),\n",
        "    epochs=10,\n",
        "    class_weight = class_weights_wav,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "model_as_json = tcn_vggish.to_json()\n",
        "with open(model_path, \"w\") as json_file:\n",
        "    json_file.write(model_as_json)"
      ],
      "metadata": {
        "id": "majS6xxh2OfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# set hyperparameters\n",
        "\n",
        "batch_size = 32\n",
        "model_path = 'vggish_model.json'\n",
        "model_weights = \"vggish_weights.h5\"\n",
        "optimizer = 'adam'\n",
        "loss = \"BinaryCrossentropy\"\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "print(model_weights)\n",
        "# Load the best checkpoint of the model \n",
        "tcn_vggish_reloaded = u.reload_tcn(model_path, model_weights, optimizer, loss, metrics)\n",
        "#tcn_vggish_reloaded = reload_tcn(model_path, model_weights, optimizer, loss, metrics)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss_vggish, test_acc_vggish = tcn_vggish_reloaded.evaluate(dataset_test.prefetch(tf.data.AUTOTUNE).map(map_function_vggish).batch(batch_size))\n",
        "print(f\"Test Loss: {test_loss_vggish:.4f}, Test Accuracy: {test_acc_vggish:.4f}\")"
      ],
      "metadata": {
        "id": "tjR_bb7zKtHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get labels\n",
        "_y = np.concatenate([y for x, y in dataset_test], axis = 0)"
      ],
      "metadata": {
        "id": "k6OoOU4Qpays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "predictions = tcn_vggish_reloaded.predict(dataset_test.prefetch(tf.data.AUTOTUNE).map(map_function_vggish).batch(batch_size))"
      ],
      "metadata": {
        "id": "KyvxU4D87AB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predictions\n",
        "np.save(\"predictions_vggish\", predictions)"
      ],
      "metadata": {
        "id": "9kiA-XZJ7Qpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load predictions\n",
        "predictions = np.load(\"predictions_vggish.npy\")"
      ],
      "metadata": {
        "id": "MilkE8Fojbfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape test labels\n",
        "vggish_test_labels_shaped = np.reshape(_y, (562,10))"
      ],
      "metadata": {
        "id": "u5FtizkWohHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save test labels\n",
        "np.save(\"vggish_test_labels_shaped\", vggish_test_labels_shaped)"
      ],
      "metadata": {
        "id": "3N6FeL-ios5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set decision threshold\n",
        "y_pred_binary = (predictions > 0.5) "
      ],
      "metadata": {
        "id": "_2-drLopGB5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get confusion matrix\n",
        "confusion = multilabel_confusion_matrix(y_true = vggish_test_labels_shaped, y_pred = y_pred_binary)"
      ],
      "metadata": {
        "id": "52q18-v5Ku0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display confusion matrix\n",
        "confusion"
      ],
      "metadata": {
        "id": "hCzqBIHLGAxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at predictions / labels\n",
        "print(predictions[10:15])\n",
        "print(test_labels_array[10:15])"
      ],
      "metadata": {
        "id": "9QOyYY6wse5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save confusion matrix\n",
        "np.save(\"confusion_vggish\", confusion)"
      ],
      "metadata": {
        "id": "KevkuCCOL0ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make classification report\n",
        "from sklearn.metrics import classification_report\n",
        "class_report = classification_report(vggish_test_labels_shaped, y_pred_binary, output_dict = True)"
      ],
      "metadata": {
        "id": "4w-I6X3wTNo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show classification report\n",
        "class_report"
      ],
      "metadata": {
        "id": "v7GuiwoPTYIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save classification report\n",
        "import pickle as pkl\n",
        "with open(\"vggish_class_report\", \"wb\") as c:\n",
        "  pkl.dump(class_report, c)"
      ],
      "metadata": {
        "id": "qWiroZOETrW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST DO NOT USE\n",
        "# def calculating_class_weights(y_true):\n",
        "#     from sklearn.utils.class_weight import compute_class_weight\n",
        "#     number_dim = np.shape(y_true)[1]\n",
        "#     weights = np.empty([number_dim, 2])\n",
        "#     for i in range(number_dim):\n",
        "#         weights[i] = compute_class_weight('balanced', classes = [0.,1.], y = y_true[:, i])\n",
        "#     return weights"
      ],
      "metadata": {
        "id": "eOsQrUVQUF-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights_wav = calculating_class_weights(test_labels_array)"
      ],
      "metadata": {
        "id": "22iDKrsQYHsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights_wav"
      ],
      "metadata": {
        "id": "pYkAW9FIYVP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST DO NOT USE\n",
        "# def get_weighted_loss(weights):\n",
        "#     def weighted_loss(y_true, y_pred):\n",
        "#         print(type(y_true))\n",
        "#         print(type(y_pred))\n",
        "#         return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
        "#     return weighted_loss"
      ],
      "metadata": {
        "id": "__2HE7rjY1KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJ2rS5g4ZKMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}