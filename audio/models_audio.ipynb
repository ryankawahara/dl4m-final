{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install keras-tcn\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Layer, BatchNormalization, Dropout, Reshape, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tcn import TCN\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fwwo1zsiZ-Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDijKhbVZwpj"
      },
      "outputs": [],
      "source": [
        "def cnn_model(input_shape):\n",
        "  \"\"\"\n",
        "  Create a Convolutional Neural Network (CNN) model for time series classification.\n",
        "\n",
        "  The CNN architecture consists of three convolutional blocks followed by fully connected layers.\n",
        "  Each convolutional block has the following layers:\n",
        "  1. Conv2D layer with 20 filters, a kernel size of (3, 3), and ReLU activation\n",
        "  2. MaxPooling2D layer with a pool size of (3, 1)\n",
        "  3. Dropout layer with a dropout rate of 0.15\n",
        "\n",
        "  After the convolutional blocks, the following fully connected layers are added:\n",
        "  1. Flatten layer to convert the 2D feature maps into a 1D feature vector\n",
        "  2. Dense layer with 64 units and ReLU activation\n",
        "  3. Dense layer with 32 units and ReLU activation\n",
        "  4. Dense layer with 10 units and softmax activation (output layer)\n",
        "\n",
        "  The model is compiled using the Adam optimizer, sparse categorical crossentropy loss, and accuracy metric.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  input_shape : tuple\n",
        "      The shape of the input data, including the number of time steps and the number of features.\n",
        "      For example, (100, 10) means 100 time steps and 10 features.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  model : keras.Model\n",
        "      A compiled Keras model with the CNN architecture.\n",
        "\n",
        "  Example\n",
        "  -------\n",
        "  >>> input_shape = (100, 10)  # 100 time steps and 10 features\n",
        "  >>> model = cnn_model(input_shape)\n",
        "  >>> print(model.summary())\n",
        "\n",
        "  # Prepare your dataset\n",
        "  >>> x_train, y_train, x_test, y_test = ...  # Load or preprocess your data\n",
        "\n",
        "  # Train the model\n",
        "  >>> history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "  # Evaluate the model\n",
        "  >>> loss, accuracy = model.evaluate(x_test, y_test)\n",
        "  >>> print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
        "\n",
        "  # Make predictions\n",
        "  >>> y_pred = model.predict(x_test)\n",
        "  >>> y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  from tensorflow import keras\n",
        "  #from keras import layers\n",
        "  print(\"here\")\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  x = keras.layers.Conv2D(filters=20, kernel_size=(3,3), activation=\"relu\")(inputs)\n",
        "  x = keras.layers.MaxPooling2D(pool_size=(3,1))(x)\n",
        "  x = keras.layers.Dropout(.15)(x)\n",
        "  x = keras.layers.Conv2D(filters=20, kernel_size=(3,3), activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling2D(pool_size=(3,1))(x)\n",
        "  x = keras.layers.Dropout(.15)(x)\n",
        "  x = keras.layers.Conv2D(filters=20, kernel_size=(3,3), activation=\"relu\")(x)\n",
        "  x = keras.layers.MaxPooling2D(pool_size=(3,1))(x)\n",
        "  x = keras.layers.Dropout(.15)(x)\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "  x = keras.layers.Dense(32, activation = \"relu\")(x)\n",
        "  outputs = keras.layers.Dense(10, activation=\"sigmoid\")(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(loss = \"BinaryFocalCrossentropy\", optimizer = \"Adam\", metrics = [\"accuracy\"])\n",
        "  #print('hi')\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tcn_model(input_shape):\n",
        "  \"\"\"\n",
        "  Create a Temporal Convolutional Network (TCN) model for time series classification.\n",
        "\n",
        "  The TCN model is composed of an Input layer, a TCN layer with 64 filters, kernel size 5, dilations = (1, 2, 4, 8, 16, 32), \n",
        "  and a Dense output layer with 10 units and a softmax activation function.\n",
        "\n",
        "  The model is compiled using the Adam optimizer, sparse categorical crossentropy loss, and accuracy metric.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  input_shape : tuple\n",
        "      The shape of the input data, including the number of time steps and the number of features.\n",
        "      For example, (100, 10) means 100 time steps and 10 features.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  model : keras.Model\n",
        "      A compiled Keras model with the TCN architecture.\n",
        "\n",
        "  Example\n",
        "  -------\n",
        "  >>> input_shape = (100, 10)  # 100 time steps and 10 features\n",
        "  >>> model = tcn_model(input_shape)\n",
        "  >>> print(model.summary())\n",
        "\n",
        "  # Prepare your dataset\n",
        "  >>> x_train, y_train, x_test, y_test = ...  # Load or preprocess your data\n",
        "\n",
        "  # Train the model\n",
        "  >>> history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "  # Evaluate the model\n",
        "  >>> loss, accuracy = model.evaluate(x_test, y_test)\n",
        "  >>> print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
        "\n",
        "  # Make predictions\n",
        "  >>> y_pred = model.predict(x_test)\n",
        "  >>> y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "  \"\"\"\n",
        "  # Hint: look at the syntax of the keras-tcn package\n",
        "  # YOUR CODE HERE\n",
        "  model = keras.models.Sequential([\n",
        "        TCN(input_shape=input_shape, nb_filters=32, dilations=[1, 2, 4, 8]),\n",
        "        keras.layers.Dense(10, activation = \"sigmoid\")\n",
        "    ])\n",
        "  \n",
        "  model.compile(optimizer=\"adam\", loss=\"BinaryFocalCrossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "  \n",
        "  return(model)"
      ],
      "metadata": {
        "id": "PL7A_hboZ5vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfGB_KXTZ1KK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}